name: nf-core CI
# This workflow runs the pipeline with the minimal test dataset to check that it completes without any syntax errors
on:
  push:
    branches:
      - main
    tags:
      - v*
  pull_request:

env:
  NXF_ANSI_LOG: false

concurrency:
  group:
    "${{ github.workflow }}-${{ github.event.pull_request.number || github.ref
    }}"
  cancel-in-progress: true

jobs:
  test:
    name:
      "Run pipeline with test data (${{ matrix.NXF_VER }} | ${{ matrix.test_name
      }} | ${{ matrix.profile }})"
    # Only run on push if this is the nf-core dev branch (merged PRs)
    if:
      "${{ github.event_name != 'push' || (github.event_name == 'push' && github.repository
      == 'Ferlab-Ste-Justine/cnv-post-processing') }}"
    runs-on: ubuntu-latest
    strategy:
      matrix:
        NXF_VER:
          - 24.10.5
          - 23.10.1
          - latest-stable
        profile:
          - "docker"
        test_name:
          - "test"

    steps:
      - name: Check out pipeline code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Copy test data from S3
        run: | # the s3 client is already installed in the ubuntu-latest image
          AWS_ACCESS_KEY_ID="${{ secrets.FERLAB_PUBLIC_DATASET_READ_AWS_ACCESS_KEY_ID }}" \
          AWS_SECRET_ACCESS_KEY="${{ secrets.FERLAB_PUBLIC_DATASET_READ_AWS_SECRET_ACCESS_KEY }}" \
          AWS_DEFAULT_REGION=ca-central-1 \
          aws s3 cp s3://ferlab-public-dataset/nextflow/cnv-post-processing/Small1000GenomesChr22/V1/data-test data-test --recursive

      - name: Set up Nextflow
        uses: nf-core/setup-nextflow@v2
        with:
          version: "${{ matrix.NXF_VER }}"

      - name: Clean up Disk space
        uses: jlumbroso/free-disk-space@v1.3.1

      - name:
          "Run pipeline with test data ${{ matrix.NXF_VER }} | ${{ matrix.test_name
          }} | ${{ matrix.profile }}"
        run: |
          nextflow run ${GITHUB_WORKSPACE} -profile ${{ matrix.test_name }},${{ matrix.profile }} --outdir ./results
